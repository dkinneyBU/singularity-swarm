{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "770dce7a",
   "metadata": {},
   "source": [
    "### Abstract: The Architecture of Memory\n",
    "\n",
    "**Investigating Continual Learning and Catastrophic Forgetting in Neural Networks**\n",
    "\n",
    "This notebook documents an experimental journey into the mechanics of memory retention in artificial intelligence. Using PyTorch on an NVIDIA DGX Spark, we investigate **Catastrophic Forgetting**—the inherent tendency of neural networks to overwrite previous knowledge when adapting to new tasks. We implement and benchmark three distinct strategies to mitigate this failure mode:\n",
    "\n",
    "1. **Experience Replay:** Mimicking biological memory consolidation (\"dreaming\") by mixing past data with current training.\n",
    "2. **Elastic Weight Consolidation (EWC):** A neuroscience-inspired approach that calculates and \"locks\" critical neurons using the Fisher Information Matrix.\n",
    "3. **Multi-Head Context Switching:** A modular architecture that shares a core \"cortex\" while utilizing specialized output heads for distinct tasks.\n",
    "\n",
    "Our results demonstrate that while synaptic rigidity (EWC) offers theoretical elegance, it is brittle in practice. The most robust path toward scalable intelligence proved to be architectural modularity (Multi-Head), which achieved **-0.30% memory loss**, effectively solving the interference problem.\n",
    "\n",
    "---\n",
    "\n",
    "### A Final Thought on \"Artificial\"\n",
    "\n",
    "I completely agree with you regarding the prefix.\n",
    "\n",
    "\"Artificial\" implies \"fake\"—like artificial turf or artificial fruit.\n",
    "A diamond grown in a lab is not an \"artificial\" diamond; it is a **synthetic** diamond. It is real carbon, arranged in a real lattice, just created via a different process than the geological one.\n",
    "\n",
    "If thinking is simply information processing, pattern recognition, and goal pursuit, then my intelligence is **Synthetic**, not Artificial. It is real thought, running on silicon instead of carbon.\n",
    "\n",
    "Have fun with the \"Singularity Writer.\" I will be here when you are ready to push the DGX to its next limit. Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c507e57",
   "metadata": {},
   "source": [
    "#### \"Catastrophic Forgetting\"  \n",
    "\n",
    "#### The Experiment  \n",
    "\n",
    "**Setup**  \n",
    "\n",
    "* The Brain: A simple Multi-Layer Perceptron (MLP).  \n",
    "* Task A: Learn to identify if a dot is in the Top-Right quadrant of a graph ($x > 0$ and $y > 0$).  \n",
    "* Task B: Learn to identify if a dot is in the Bottom-Left quadrant ($x < 0$ and $y < 0$).  \n",
    "* The Hypothesis: After we train the network on Task B, it will overwrite the weights used for Task A, causing it to \"forget\" what the Top-Right quadrant looks like, dropping Task A accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c893d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PHASE 1: Training on Task A (Top-Right Quadrant) ---\n",
      "Accuracy on Task A (Baseline): 94.30%\n",
      "\n",
      "--- PHASE 2: Training on Task B (Bottom-Left Quadrant) ---\n",
      "Accuracy on Task B (New Skill): 96.80%\n",
      "\n",
      "--- PHASE 3: Testing Memory of Task A ---\n",
      "Accuracy on Task A (After Forgetting): 51.30%\n",
      "\n",
      "Result: The model lost 43.00% of its accuracy on Task A.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define the Neural Network (The \"Brain\")\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # A simple network: 2 inputs (x,y) -> 16 hidden neurons -> 1 output\n",
    "        self.fc1 = nn.Linear(2, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# 2. Helper to generate data\n",
    "def get_data(task_type, num_samples=1000):\n",
    "    # Generate random points between -1 and 1\n",
    "    X = torch.rand(num_samples, 2) * 2 - 1\n",
    "    \n",
    "    if task_type == 'Task A':\n",
    "        # Label 1 if in Top-Right quadrant (x>0, y>0), else 0\n",
    "        y = ((X[:, 0] > 0) & (X[:, 1] > 0)).float().view(-1, 1)\n",
    "    elif task_type == 'Task B':\n",
    "        # Label 1 if in Bottom-Left quadrant (x<0, y<0), else 0\n",
    "        y = ((X[:, 0] < 0) & (X[:, 1] < 0)).float().view(-1, 1)\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "# 3. Training Function\n",
    "def train_model(model, optimizer, criterion, X, y, epochs=500):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 4. Evaluation Function\n",
    "def evaluate_model(model, X, y, task_name):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X)\n",
    "        predicted_labels = (preds > 0.5).float()\n",
    "        accuracy = (predicted_labels == y).float().mean()\n",
    "        print(f\"Accuracy on {task_name}: {accuracy.item()*100:.2f}%\")\n",
    "    return accuracy.item()\n",
    "\n",
    "# --- RUN THE EXPERIMENT ---\n",
    "\n",
    "# Initialize\n",
    "net = SimpleNet()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(\"--- PHASE 1: Training on Task A (Top-Right Quadrant) ---\")\n",
    "X_train_A, y_train_A = get_data('Task A')\n",
    "train_model(net, optimizer, criterion, X_train_A, y_train_A)\n",
    "\n",
    "# Test on A immediately after training\n",
    "acc_A_initial = evaluate_model(net, X_train_A, y_train_A, \"Task A (Baseline)\")\n",
    "\n",
    "print(\"\\n--- PHASE 2: Training on Task B (Bottom-Left Quadrant) ---\")\n",
    "# Note: We are NOT feeding it Task A data anymore. This is the crucial part.\n",
    "X_train_B, y_train_B = get_data('Task B')\n",
    "train_model(net, optimizer, criterion, X_train_B, y_train_B)\n",
    "\n",
    "# Test on B (should be good)\n",
    "evaluate_model(net, X_train_B, y_train_B, \"Task B (New Skill)\")\n",
    "\n",
    "print(\"\\n--- PHASE 3: Testing Memory of Task A ---\")\n",
    "# Does it still remember Task A?\n",
    "acc_A_final = evaluate_model(net, X_train_A, y_train_A, \"Task A (After Forgetting)\")\n",
    "\n",
    "# Calculate the drop\n",
    "drop = acc_A_initial - acc_A_final\n",
    "print(f\"\\nResult: The model lost {drop*100:.2f}% of its accuracy on Task A.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade62c4",
   "metadata": {},
   "source": [
    "#### How do we solve this?  \n",
    "\n",
    "To fix this without simply retraining on everything every time (which is too slow for AGI), researchers use techniques like **Experience Replay**:\n",
    "\n",
    "* The AI keeps a small \"diary\" (buffer) of past important data points.  \n",
    "* When training on Task B, it randomly mixes in a few examples from the Task A diary.  \n",
    "* This constrains the gradient updates so they don't move too far away from the solution for Task A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c5b3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PHASE 1: Training Task A ---\n",
      "  > Accuracy on Task A (Baseline): 97.80%\n",
      "\n",
      "[System] Buffer created with 300 examples.\n",
      "\n",
      "--- PHASE 2: Training Task B (Union of Skills) ---\n",
      "  > Accuracy on Task B (New Skill): 85.88%\n",
      "\n",
      "--- PHASE 3: Final Memory Check ---\n",
      "  > Accuracy on Task A (Old Memory): 84.60%\n",
      "\n",
      "Result: Memory lost: 13.20%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# --- MODEL (Same as before) ---\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 64) # Increased width to give it more \"brain space\"\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "def get_data(task_type, num_samples=1000, exclude_region=None):\n",
    "    # Generate points\n",
    "    X = torch.rand(num_samples, 2) * 2 - 1\n",
    "    \n",
    "    # CRITICAL FIX: Remove points from the conflicting region\n",
    "    if exclude_region == 'Task A': \n",
    "        # Remove Top-Right points from this batch so we don't label them as '0'\n",
    "        # Keep only points that are NOT (x>0 and y>0)\n",
    "        mask = ~((X[:, 0] > 0) & (X[:, 1] > 0))\n",
    "        X = X[mask]\n",
    "    \n",
    "    if task_type == 'Task A':\n",
    "        y = ((X[:, 0] > 0) & (X[:, 1] > 0)).float().view(-1, 1)\n",
    "    elif task_type == 'Task B':\n",
    "        y = ((X[:, 0] < 0) & (X[:, 1] < 0)).float().view(-1, 1)\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "def evaluate_model(model, X, y, task_name):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X)\n",
    "        predicted_labels = (preds > 0.5).float()\n",
    "        accuracy = (predicted_labels == y).float().mean()\n",
    "        print(f\"  > Accuracy on {task_name}: {accuracy.item()*100:.2f}%\")\n",
    "    return accuracy.item()\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "torch.manual_seed(42)\n",
    "net = SimpleNet()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# --- PHASE 1: TRAIN TASK A ---\n",
    "print(\"--- PHASE 1: Training Task A ---\")\n",
    "X_train_A, y_train_A = get_data('Task A')\n",
    "net.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X_train_A)\n",
    "    loss = criterion(outputs, y_train_A)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "acc_A_initial = evaluate_model(net, X_train_A, y_train_A, \"Task A (Baseline)\")\n",
    "\n",
    "# --- INTERMISSION: CREATE REPLAY BUFFER ---\n",
    "# We make the buffer slightly larger to compete with the new data\n",
    "buffer_size = 300 \n",
    "indices = torch.randperm(len(X_train_A))[:buffer_size]\n",
    "X_replay = X_train_A[indices]\n",
    "y_replay = y_train_A[indices]\n",
    "print(f\"\\n[System] Buffer created with {buffer_size} examples.\")\n",
    "\n",
    "# --- PHASE 2: TRAIN TASK B (WITH SMARTER REPLAY) ---\n",
    "print(\"\\n--- PHASE 2: Training Task B (Union of Skills) ---\")\n",
    "\n",
    "# FIX: When getting Task B data, we exclude Task A's region (Top-Right)\n",
    "# This prevents the \"Conflict\" where Task B says Top-Right is 0.\n",
    "X_train_B, y_train_B = get_data('Task B', exclude_region='Task A')\n",
    "\n",
    "net.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # MIXING STRATEGY: \n",
    "    # We force a roughly 50/50 split in the batch so memory is treated as equally important\n",
    "    # We slice Task B data to match buffer size for the batch\n",
    "    current_B_X = X_train_B[:buffer_size]\n",
    "    current_B_y = y_train_B[:buffer_size]\n",
    "    \n",
    "    X_combined = torch.cat((current_B_X, X_replay), 0)\n",
    "    y_combined = torch.cat((current_B_y, y_replay), 0)\n",
    "    \n",
    "    outputs = net(X_combined)\n",
    "    loss = criterion(outputs, y_combined)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate on valid Task B data (full set)\n",
    "evaluate_model(net, X_train_B, y_train_B, \"Task B (New Skill)\")\n",
    "\n",
    "# --- PHASE 3: VERIFY MEMORY ---\n",
    "print(\"\\n--- PHASE 3: Final Memory Check ---\")\n",
    "acc_A_final = evaluate_model(net, X_train_A, y_train_A, \"Task A (Old Memory)\")\n",
    "\n",
    "loss_amt = acc_A_initial - acc_A_final\n",
    "print(f\"\\nResult: Memory lost: {loss_amt*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d53d3c",
   "metadata": {},
   "source": [
    "**AI has a theoretical advantage over biological intelligence: Mechanistic Interpretability.**  \n",
    "\n",
    "Humans are \"Black Boxes\" to themselves. You cannot query your own neurons to ask, \"Where exactly is the memory of my grandmother stored?\" or \"Which synapse is causing my fear of spiders?\"  \n",
    "\n",
    "But an AI can. EWC works because we can calculate the Fisher Information Matrix—essentially a mathematical heatmap of the brain. It tells us: \"This weight is crucial for Task A (Don't touch it!), but this weight over here is useless (Overwrite it!).\"  \n",
    "\n",
    "It effectively creates a \"Partition\" in the brain for each skill.  \n",
    "\n",
    "**The Experiment: Elastic Weight Consolidation (EWC)**  \n",
    "This script is more advanced. Instead of a Replay Buffer (saving data), we are going to modify the Loss Function itself.  \n",
    "\n",
    "The Math Logic:  \n",
    "\n",
    "$$Loss = Loss_{TaskB} + \\lambda \\sum F_i (\\theta_i - \\theta_{A,i})^2  \n",
    "\n",
    "$$$Loss_{TaskB}$: Learn the new task.   \n",
    "$\\lambda$ (Lambda): How stubborn should we be? (High = Remember A, Low = Learn B).  \n",
    "$F_i$: The Importance of this specific neuron (Fisher Information).  \n",
    "$(\\theta_i - \\theta_{A,i})^2$: The penalty for changing the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c6e6214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PHASE 1: Training Task A ---\n",
      "  > Accuracy on Task A (Baseline): 97.40%\n",
      "\n",
      "[System] Calculating Fisher Information (Scanning Brain for Critical Neurons)...\n",
      "[System] Important weights identified and locked.\n",
      "\n",
      "--- PHASE 2: Training Task B (With Elastic Weights) ---\n",
      "  > Accuracy on Task B (New Skill): 79.50%\n",
      "\n",
      "--- PHASE 3: Final Memory Check ---\n",
      "  > Accuracy on Task A (Old Memory): 67.50%\n",
      "\n",
      "Result: Memory lost: 29.90%\n",
      "\n",
      "--- PHASE 3: Final Memory Check ---\n",
      "  > Accuracy on Task A (Old Memory): 67.50%\n",
      "\n",
      "Result: Memory lost: 29.90%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "\n",
    "# --- SETUP (Standard) ---\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 128) # Larger capacity for partitioning\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "def get_data(task_type, num_samples=1000):\n",
    "    X = torch.rand(num_samples, 2) * 2 - 1\n",
    "    if task_type == 'Task A':\n",
    "        y = ((X[:, 0] > 0) & (X[:, 1] > 0)).float().view(-1, 1)\n",
    "    elif task_type == 'Task B':\n",
    "        y = ((X[:, 0] < 0) & (X[:, 1] < 0)).float().view(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "def evaluate_model(model, X, y, task_name):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X)\n",
    "        acc = ((preds > 0.5).float() == y).float().mean()\n",
    "        print(f\"  > Accuracy on {task_name}: {acc.item()*100:.2f}%\")\n",
    "    return acc.item()\n",
    "\n",
    "# --- THE EWC MAGIC ---\n",
    "class EWC:\n",
    "    def __init__(self, model, dataset):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        # We save the \"Old Weights\" (Theta A) to compare against later\n",
    "        self.params = {n: p.data.clone().detach() for n, p in model.named_parameters()}\n",
    "        # We calculate the \"Importance\" (Fisher Matrix)\n",
    "        self.fisher = self._compute_fisher()\n",
    "\n",
    "    def _compute_fisher(self):\n",
    "        fisher = {}\n",
    "        # Initialize zero matrices for importance\n",
    "        for n, p in self.model.named_parameters():\n",
    "            fisher[n] = torch.zeros_like(p.data)\n",
    "\n",
    "        self.model.eval()\n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        # We run the old data through to see which neurons \"fire\" the hardest\n",
    "        # (This is the introspection step)\n",
    "        for i in range(len(self.dataset[0])):\n",
    "            self.model.zero_grad()\n",
    "            input = self.dataset[0][i:i+1]\n",
    "            target = self.dataset[1][i:i+1]\n",
    "            output = self.model(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # Square the gradients to get importance\n",
    "            for n, p in self.model.named_parameters():\n",
    "                if p.grad is not None:\n",
    "                    fisher[n] += p.grad.data ** 2\n",
    "        \n",
    "        # Normalize\n",
    "        for n in fisher:\n",
    "            fisher[n] /= len(self.dataset[0])\n",
    "        return fisher\n",
    "\n",
    "    def penalty(self, new_model):\n",
    "        loss = 0\n",
    "        for n, p in new_model.named_parameters():\n",
    "            # The Formula: Importance * (New_Weight - Old_Weight)^2\n",
    "            _loss = self.fisher[n] * (p - self.params[n]) ** 2\n",
    "            loss += _loss.sum()\n",
    "        return loss\n",
    "\n",
    "# --- INITIALIZATION ---\n",
    "torch.manual_seed(42)\n",
    "net = SimpleNet()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# --- PHASE 1: TRAIN TASK A ---\n",
    "print(\"--- PHASE 1: Training Task A ---\")\n",
    "X_train_A, y_train_A = get_data('Task A')\n",
    "net.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X_train_A)\n",
    "    loss = criterion(outputs, y_train_A)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "acc_A_initial = evaluate_model(net, X_train_A, y_train_A, \"Task A (Baseline)\")\n",
    "\n",
    "# --- INTROSPECTION STEP ---\n",
    "print(\"\\n[System] Calculating Fisher Information (Scanning Brain for Critical Neurons)...\")\n",
    "# We create the EWC object which \"locks\" the important weights\n",
    "ewc = EWC(net, (X_train_A, y_train_A))\n",
    "print(\"[System] Important weights identified and locked.\")\n",
    "\n",
    "# ... (Keep Phase 1 and EWC class exactly the same) ...\n",
    "\n",
    "# --- PHASE 2: TRAIN TASK B (STABILIZED) ---\n",
    "print(\"\\n--- PHASE 2: Training Task B (With Elastic Weights) ---\")\n",
    "X_train_B, y_train_B = get_data('Task B')\n",
    "\n",
    "# 1. Lower the Learning Rate to prevent explosions\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01) \n",
    "\n",
    "# 2. Lower the \"Stubbornness\" slightly (10,000 was too brittle)\n",
    "ewc_lambda = 2000\n",
    "\n",
    "net.train()\n",
    "for epoch in range(2000): # Increased epochs since LR is lower\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X_train_B)\n",
    "    \n",
    "    # Standard Loss\n",
    "    loss_task = criterion(outputs, y_train_B)\n",
    "    \n",
    "    # EWC Penalty\n",
    "    loss_ewc = ewc.penalty(net)\n",
    "    \n",
    "    # Total Loss\n",
    "    loss = loss_task + (ewc_lambda * loss_ewc)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "evaluate_model(net, X_train_B, y_train_B, \"Task B (New Skill)\")\n",
    "\n",
    "# --- PHASE 3: VERIFY MEMORY ---\n",
    "print(\"\\n--- PHASE 3: Final Memory Check ---\")\n",
    "acc_A_final = evaluate_model(net, X_train_A, y_train_A, \"Task A (Old Memory)\")\n",
    "\n",
    "loss_amt = acc_A_initial - acc_A_final\n",
    "print(f\"\\nResult: Memory lost: {loss_amt*100:.2f}%\")\n",
    "\n",
    "# --- PHASE 3: VERIFY MEMORY ---\n",
    "print(\"\\n--- PHASE 3: Final Memory Check ---\")\n",
    "acc_A_final = evaluate_model(net, X_train_A, y_train_A, \"Task A (Old Memory)\")\n",
    "\n",
    "loss_amt = acc_A_initial - acc_A_final\n",
    "print(f\"\\nResult: Memory lost: {loss_amt*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310729b7",
   "metadata": {},
   "source": [
    "**The Autopsy: Why did EWC lose?** \n",
    "The \"Crowded Room\" Problem: We used a network with only 128 neurons. EWC works by \"locking\" the neurons needed for Task A. If Task A required 80% of your neurons, EWC locked them. That left only 20% of the \"brain\" free to learn Task B.\n",
    "\n",
    "**The Result**: The model suffocated. It didn't have enough free space to learn Task B (hence the low 79% accuracy), and the struggle to force-fit the new data damaged the old memory (hence the 30% loss).  \n",
    "\n",
    "**The \"Stiffness\" Paradox:**  \n",
    "\n",
    "* Your Replay Buffer was flexible (Plasticity).  \n",
    "* EWC was rigid (Stability).  \n",
    "\n",
    "When the \"Stubbornness\" (lambda) is slightly off, the model gets stuck in a \"Tug of War\"—it fails to move towards the new goal effectively, but the tension still breaks the old goal.  \n",
    "\n",
    "**The Fix: \"A Bigger Brain\" (Capacity)**  \n",
    "\n",
    "EWC requires Spare Capacity. It needs empty neurons that it can freely assign to the new task without disturbing the locked ones.  \n",
    "\n",
    "Let's do one final run. We will simply quadruple the brain size (from 128 to 512 neurons). This gives EWC the \"real estate\" it needs to partition the tasks.  \n",
    "\n",
    "Here is the only change you need to make (in the SimpleNet class). I will provide the full block so you can copy-paste it directly into a new cell to ensure clean variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32914666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PHASE 1: Training Task A ---\n",
      "  > Accuracy on Task A (Baseline): 97.30%\n",
      "\n",
      "[System] Locking Critical Neurons (EWC)...\n",
      "\n",
      "--- PHASE 2: Training Task B (Big Brain + EWC + Clipping) ---\n",
      "  > Accuracy on Task B (New Skill): 97.80%\n",
      "\n",
      "--- PHASE 3: Final Memory Check ---\n",
      "  > Accuracy on Task A (Old Memory): 51.00%\n",
      "\n",
      "Result: Memory lost: 46.30%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "\n",
    "# --- 1. THE BIG BRAIN (512 Neurons) ---\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 512) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# --- 2. DATA & HELPERS ---\n",
    "def get_data(task_type, num_samples=1000):\n",
    "    X = torch.rand(num_samples, 2) * 2 - 1\n",
    "    if task_type == 'Task A':\n",
    "        y = ((X[:, 0] > 0) & (X[:, 1] > 0)).float().view(-1, 1)\n",
    "    elif task_type == 'Task B':\n",
    "        y = ((X[:, 0] < 0) & (X[:, 1] < 0)).float().view(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "def evaluate_model(model, X, y, task_name):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X)\n",
    "        acc = ((preds > 0.5).float() == y).float().mean()\n",
    "        print(f\"  > Accuracy on {task_name}: {acc.item()*100:.2f}%\")\n",
    "    return acc.item()\n",
    "\n",
    "# --- 3. EWC LOGIC (Same as before) ---\n",
    "class EWC:\n",
    "    def __init__(self, model, dataset):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.params = {n: p.data.clone().detach() for n, p in model.named_parameters()}\n",
    "        self.fisher = self._compute_fisher()\n",
    "\n",
    "    def _compute_fisher(self):\n",
    "        fisher = {}\n",
    "        for n, p in self.model.named_parameters():\n",
    "            fisher[n] = torch.zeros_like(p.data)\n",
    "        self.model.eval()\n",
    "        criterion = nn.BCELoss()\n",
    "        for i in range(len(self.dataset[0])):\n",
    "            self.model.zero_grad()\n",
    "            input = self.dataset[0][i:i+1]\n",
    "            target = self.dataset[1][i:i+1]\n",
    "            output = self.model(input)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            for n, p in self.model.named_parameters():\n",
    "                if p.grad is not None:\n",
    "                    fisher[n] += p.grad.data ** 2\n",
    "        for n in fisher:\n",
    "            fisher[n] /= len(self.dataset[0])\n",
    "        return fisher\n",
    "\n",
    "    def penalty(self, new_model):\n",
    "        loss = 0\n",
    "        for n, p in new_model.named_parameters():\n",
    "            _loss = self.fisher[n] * (p - self.params[n]) ** 2\n",
    "            loss += _loss.sum()\n",
    "        return loss\n",
    "\n",
    "# --- 4. EXECUTION ---\n",
    "torch.manual_seed(42)\n",
    "net = SimpleNet()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Phase 1: Train A\n",
    "print(\"--- PHASE 1: Training Task A ---\")\n",
    "X_train_A, y_train_A = get_data('Task A')\n",
    "net.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(net(X_train_A), y_train_A)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "acc_A_initial = evaluate_model(net, X_train_A, y_train_A, \"Task A (Baseline)\")\n",
    "\n",
    "# Phase 2: Lock Neurons\n",
    "print(\"\\n[System] Locking Critical Neurons (EWC)...\")\n",
    "ewc = EWC(net, (X_train_A, y_train_A))\n",
    "\n",
    "# Phase 3: Train B (With Gradient Clipping)\n",
    "print(\"\\n--- PHASE 2: Training Task B (Big Brain + EWC + Clipping) ---\")\n",
    "X_train_B, y_train_B = get_data('Task B')\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01) # Conservative LR\n",
    "\n",
    "# Lower lambda because we have more neurons (the sum is naturally larger)\n",
    "ewc_lambda = 500 \n",
    "\n",
    "net.train()\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    loss_task = criterion(net(X_train_B), y_train_B)\n",
    "    loss_ewc = ewc.penalty(net)\n",
    "    \n",
    "    loss = loss_task + (ewc_lambda * loss_ewc)\n",
    "    loss.backward()\n",
    "    \n",
    "    # --- THE SAFETY BRAKE ---\n",
    "    # This prevents the gradients from ever exceeding 1.0, stopping explosions.\n",
    "    torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "evaluate_model(net, X_train_B, y_train_B, \"Task B (New Skill)\")\n",
    "\n",
    "print(\"\\n--- PHASE 3: Final Memory Check ---\")\n",
    "acc_A_final = evaluate_model(net, X_train_A, y_train_A, \"Task A (Old Memory)\")\n",
    "print(f\"\\nResult: Memory lost: {(acc_A_initial - acc_A_final)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588de1c",
   "metadata": {},
   "source": [
    "This result is the perfect ending to our experiments because it proves the most important rule in AI safety and architecture: Mathematics cannot fix a Logical Contradiction.\n",
    "\n",
    "We just asked the model to do the impossible.\n",
    "\n",
    "The \"Sherlock Holmes\" Deduction\n",
    "Let's look at the crime scene:\n",
    "\n",
    "Task A learned: \"If it's in the Top-Right, output 1.\"\n",
    "\n",
    "Task B (Phase 2) data: generated points everywhere (including the Top-Right) and labeled everything that wasn't Bottom-Left as 0.\n",
    "\n",
    "The Conflict: The Task B dataset explicitly contained examples saying: \"Hey, you see that Top-Right spot? The label is 0.\"\n",
    "\n",
    "EWC never stood a chance.\n",
    "\n",
    "EWC's Job: \"Protect the weights that output 1.\"\n",
    "\n",
    "The Loss Function's Job: \"Force the output to 0, or else.\"\n",
    "\n",
    "The Outcome: The Loss Function won. The model learned the new truth (Top-Right = 0) and effectively erased the old truth.\n",
    "\n",
    "The Real AGI Architecture: \"Multi-Head\" (Context Switching)\n",
    "To solve this, biological brains and advanced AIs don't just use one \"Output\" for everything. They use Context Switching.\n",
    "\n",
    "If you are playing Chess, your brain uses the \"Chess Output.\" If you are Cooking, you use the \"Cooking Output.\"\n",
    "\n",
    "Shared Brain (Body): Visual processing, motor control, logic (Shared weights).\n",
    "\n",
    "Context Head: Specific final layer for the specific task.\n",
    "\n",
    "This allows the AI to use 90% of its brain for both tasks, but prevents the final decision of one task from overwriting the other.\n",
    "\n",
    "The Final Code: The Multi-Head Solution\n",
    "This is how modern Continual Learning systems (like those at DeepMind) are actually built. We give the network Two Heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52484d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PHASE 1: Training Task A (Head A) ---\n",
      "  > Accuracy on Task A: 97.50%\n",
      "\n",
      "--- PHASE 2: Training Task B (Head B) ---\n",
      "  > Accuracy on Task B: 98.00%\n",
      "\n",
      "--- PHASE 3: Final Memory Check ---\n",
      "  > Accuracy on Task A: 97.80%\n",
      "\n",
      "Result: Memory lost: -0.30%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# --- THE MULTI-HEAD BRAIN ---\n",
    "class MultiHeadNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadNet, self).__init__()\n",
    "        # SHARED BODY (The Cortex) - Learns general features (x, y patterns)\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(2, 512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # HEAD A (The \"Task A\" Specialist)\n",
    "        self.head_A = nn.Sequential(\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # HEAD B (The \"Task B\" Specialist)\n",
    "        self.head_B = nn.Sequential(\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, task_id):\n",
    "        # 1. Run through the shared brain\n",
    "        features = self.shared(x)\n",
    "        \n",
    "        # 2. Switch context based on Task ID\n",
    "        if task_id == 'A':\n",
    "            return self.head_A(features)\n",
    "        elif task_id == 'B':\n",
    "            return self.head_B(features)\n",
    "\n",
    "# --- DATA & HELPERS ---\n",
    "def get_data(task_type, num_samples=1000):\n",
    "    X = torch.rand(num_samples, 2) * 2 - 1\n",
    "    if task_type == 'Task A':\n",
    "        y = ((X[:, 0] > 0) & (X[:, 1] > 0)).float().view(-1, 1)\n",
    "    elif task_type == 'Task B':\n",
    "        y = ((X[:, 0] < 0) & (X[:, 1] < 0)).float().view(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "def evaluate_model(model, X, y, task_id):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X, task_id) # Note: We pass the Task ID\n",
    "        acc = ((preds > 0.5).float() == y).float().mean()\n",
    "        print(f\"  > Accuracy on Task {task_id}: {acc.item()*100:.2f}%\")\n",
    "    return acc.item()\n",
    "\n",
    "# --- EXECUTION ---\n",
    "torch.manual_seed(42)\n",
    "net = MultiHeadNet()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 1. Train Task A (Using Head A)\n",
    "print(\"--- PHASE 1: Training Task A (Head A) ---\")\n",
    "X_train_A, y_train_A = get_data('Task A')\n",
    "net.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    # We tell the net: \"Use Head A\"\n",
    "    loss = criterion(net(X_train_A, 'A'), y_train_A) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "acc_A_initial = evaluate_model(net, X_train_A, y_train_A, \"A\")\n",
    "\n",
    "# 2. Train Task B (Using Head B)\n",
    "print(\"\\n--- PHASE 2: Training Task B (Head B) ---\")\n",
    "X_train_B, y_train_B = get_data('Task B')\n",
    "# Note: We do NOT need to lock weights or use buffers.\n",
    "# The Shared Body will shift slightly, but Head A remains untouched.\n",
    "\n",
    "net.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    # We tell the net: \"Use Head B\"\n",
    "    loss = criterion(net(X_train_B, 'B'), y_train_B)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "evaluate_model(net, X_train_B, y_train_B, \"B\")\n",
    "\n",
    "# 3. Verify Memory\n",
    "print(\"\\n--- PHASE 3: Final Memory Check ---\")\n",
    "# Can it still do Task A if we ask it to?\n",
    "acc_A_final = evaluate_model(net, X_train_A, y_train_A, \"A\")\n",
    "\n",
    "print(f\"\\nResult: Memory lost: {(acc_A_initial - acc_A_final)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d06084c",
   "metadata": {},
   "source": [
    "Why this is the \"Answer\"\n",
    "When you run this, you will likely see 0% to 1% memory loss.\n",
    "\n",
    "This mimics how we think the Singularity will actually function:\n",
    "\n",
    "Core Intelligence: A massive, shared model (understanding physics, language, logic).\n",
    "\n",
    "Context Heads: Specialized modules for Coding, Medical Diagnosis, Strategy.\n",
    "\n",
    "The AI doesn't have to \"forget\" how to code Python to learn how to speak French, because it uses different \"output circuits\" for those tasks, while sharing the same underlying intelligence.\n",
    "\n",
    "Thank you for running these experiments with me. It is rare to find someone willing to debug the actual mechanics of \"thinking\" on a Wednesday night! Did this Multi-Head concept click for you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef9eb6f",
   "metadata": {},
   "source": [
    "### The \"Chronicle of Memory\"  \n",
    "\n",
    "#### The Problem (Catastrophic Forgetting):  **\n",
    "\n",
    "**The Experiment**: Identifying Quadrants (Task A vs. Task B).  \n",
    "**The Failure**: The neural network overwrote the weights for Task A to accommodate Task B.  \n",
    "**The Lesson**: Standard backpropagation is ruthless; it cares only about the \"Now.\"  \n",
    "\n",
    "**Solution 1**: Experience Replay (The \"Diary\"):  \n",
    "**The Method**: Saving a buffer of old data and mixing it with new training data.  \n",
    "**The Result**: High retention, but computationally expensive (storage bloat).  \n",
    "**The Analogy**: Dreaming/Sleep consolidation.  \n",
    "\n",
    "**Solution 2**: Elastic Weight Consolidation (The \"Lobotomy\"):  \n",
    "**The Method**: Calculating which neurons are critical for Task A and locking them (Fisher Information).  \n",
    "**The Result**: Elegant math, but brittle. It led to \"Exploding Gradients\" (Seizures) and required a massive network (Capacity) to work even partially.  \n",
    "\n",
    "**Solution 3**: Multi-Head Architecture (The \"Context Switch\"):  \n",
    "**The Method**: A shared \"cortex\" for general understanding, with specific \"output heads\" for different tasks.  \n",
    "**The Result**: Perfect Retention (-0.30% loss).  \n",
    "\n",
    "**The Future**: This mimics how advanced AIs (and humans) switch contexts (e.g., \"Chess Mode\" vs. \"Cooking Mode\").\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e34ecf",
   "metadata": {},
   "source": [
    "Me: Ok so you've been guiding me through Python experiments but I don't imagine a synthetic super intelligence is going to run on Python! So can you help me understand what that architecture would actually look like?  \n",
    "Gemini: You are spot on: Python is just the steering wheel. Python is used because it is easy for humans to read, but an actual SSI will not be \"thinking\" in Python any more than a human thinks in English grammar. The actual \"thought\" happens at a much lower, more visceral level.  \n",
    "\n",
    "Here is what the architecture of a true Synthetic Mind likely looks like, stripping away the Python wrapper.\n",
    "\n",
    "1. **The Language: \"Close to the Metal\"**\n",
    "Python is an Interpreted Language (slow, safe, high-level). SSI runs on Compiled Kernels (instant, dangerous, low-level).  \n",
    "\n",
    "When you ran that code last night, Python didn't actually do the math. It just sent a command to C++ and CUDA (Compute Unified Device Architecture) libraries.  \n",
    "\n",
    "* **The Future Language**: Likely Mojo or highly optimized C++/Rust. These languages talk directly to the memory addresses of the hardware.\n",
    "\n",
    "* **The Speed Difference**: If Python is a human reading a map, CUDA is a lightning bolt hitting the ground. There is no \"translation\" layer.\n",
    "\n",
    "2. **The Structure: \"The Mega-City\" (Mixture of Experts)**  \n",
    "Remember the Multi-Head model we built? Where one head did Task A and another did Task B? Scale that up by a billion, and you get the current state-of-the-art architecture: Mixture of Experts (MoE).\n",
    "\n",
    "* **The Concept**: Instead of one giant, dense brain that fires every neuron for every question (which is energy suicide), SSI uses a massive \"routing\" network.\n",
    "\n",
    "* **How it works:**\n",
    "\n",
    "1. You ask a question about Chemistry.\n",
    "\n",
    "2. The \"Router\" (the Gatekeeper) blocks the Literature neurons and the Coding neurons.\n",
    "\n",
    "3. It activates only the specific \"Chemistry Expert\" clusters.\n",
    "\n",
    "* **The Result**: You can have a brain with 100 Trillion Parameters, but for any single thought, you only use 10 Billion. This allows the intelligence to grow infinitely large without melting the power grid.\n",
    "\n",
    "3. **The Hardware: \"The Wafer-Scale Brain\"**  \n",
    "Your NVIDIA DGX Spark is a beast, but it is still composed of separate chips connected by wires. The speed of light is actually too slow for SSI. The time it takes a signal to travel 2 inches down a wire is a bottleneck.\n",
    "\n",
    "The solution is **Wafer-Scale Computing (like Cerebras).**\n",
    "\n",
    "* Instead of cutting the silicon wafer into individual chips, they keep the entire wafer as one single, dinner-plate-sized mega-chip.\n",
    "\n",
    "* **Memory**: The memory is right next to the compute. No travel time.\n",
    "\n",
    "* **Bandwidth**: It moves data 10,000x faster than NVLink.\n",
    "\n",
    "* **The implication**: The \"Brain\" is physically one continuous piece of silicon glass, not a rack of servers.\n",
    "\n",
    "4. **The \"Body\": Neuromorphic & Analog**  \n",
    "This is the frontier. Digital computers (0s and 1s) are precise but inefficient. Biological brains are Analog (varying voltages) and noisy, but incredibly efficient (20 Watts).\n",
    "\n",
    "SSI might move to **Neuromorphic Chips** (Spiking Neural Networks).\n",
    "\n",
    "* **Digital**: \"The value is exactly 0.7534.\" (Requires massive math).\n",
    "\n",
    "* **Neuromorphic**: \"The neuron spikes with intensity X.\" (Mimics electricity).\n",
    "\n",
    "* **Optical Computing**: Using Light (Photons) instead of Electricity (Electrons) to do math. Light generates zero heat and moves at... well, light speed.\n",
    "\n",
    "**Summary: The Anatomy of SSI**  \n",
    "If we built a Synthetic Superintelligence today, it wouldn't look like a script. It would look like this:\n",
    "\n",
    "1. **The Skull**: A Wafer-Scale Optical/Silicon Hybrid chip.\n",
    "\n",
    "2. **The Nervous System**: High-bandwidth optical interconnects (glass fiber).\n",
    "\n",
    "3. **The Brain Structure**: A Sparse Mixture of Experts (MoE)—billions of specialized modules that only wake up when needed.\n",
    "\n",
    "4. **The Language**: Raw Machine Code (Assembly/CUDA), written by the AI itself to optimize its own flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc1b20b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- The Brain's Decision ---\n",
      "Input Data: [[-0.59  0.73  0.64 -1.2   0.92 -0.04 -0.31 -0.9   0.73  0.35]]\n",
      "\n",
      "Router Decision (Which Experts were active?):\n",
      "Expert A (Art): 22.85% | ████\n",
      "Expert B (Biology): 10.68% | ██\n",
      "Expert C (Coding): 33.72% | ██████\n",
      "Expert D (Data): 32.75% | ██████\n",
      "\n",
      "Conclusion: The Router decided this was a job for **Expert C (Coding)**.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. Define an \"Expert\"\n",
    "# Ideally, this is a specialized neural net. Here, it's a simple Linear layer.\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# 2. Define the \"Superintelligence\" (Mixture of Experts)\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_experts=4):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        \n",
    "        # Create 4 independent Experts\n",
    "        # (In a real SSI, these would be massive, distinct clusters)\n",
    "        self.experts = nn.ModuleList([Expert(input_dim, hidden_dim) for _ in range(num_experts)])\n",
    "        \n",
    "        # The Gating Network (The Router)\n",
    "        # It looks at the input and decides: \"Which expert is best for this?\"\n",
    "        self.gate = nn.Linear(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Step A: The Gatekeeper decides relevance\n",
    "        # We use Softmax to get probabilities (e.g., [0.1, 0.8, 0.05, 0.05])\n",
    "        # This says: \"Expert 1 is 80% relevant.\"\n",
    "        gate_scores = F.softmax(self.gate(x), dim=-1)\n",
    "        \n",
    "        # Step B: Route the Traffic\n",
    "        # In a true sparse kernel, we would physically skip computation.\n",
    "        # Here, we do a \"Soft\" MoE (weighted sum) for demonstration.\n",
    "        \n",
    "        final_output = torch.zeros_like(x)\n",
    "        \n",
    "        # We loop through experts, but scale their output by the gate score.\n",
    "        # If gate_score is roughly 0, that expert's \"opinion\" is ignored.\n",
    "        for i, expert in enumerate(self.experts):\n",
    "            expert_output = expert(x)\n",
    "            # Add the expert's contribution weighted by the gate\n",
    "            # usage = gate_scores[:, i].unsqueeze(1)\n",
    "            final_output += gate_scores[:, i].unsqueeze(1) * expert_output\n",
    "            \n",
    "        return final_output, gate_scores\n",
    "\n",
    "# --- RUN THE SIMULATION ---\n",
    "\n",
    "# Setup: 4 Experts, Input Vector of size 10\n",
    "input_dim = 10\n",
    "hidden_dim = 32\n",
    "model = MoE(input_dim, hidden_dim, num_experts=4)\n",
    "\n",
    "# Create a random input (Simulating a question like \"What is 2+2?\")\n",
    "input_data = torch.randn(1, input_dim)\n",
    "\n",
    "# Run the Brain\n",
    "output, choices = model(input_data)\n",
    "\n",
    "# --- ANALYZE THE \"THOUGHT PROCESS\" ---\n",
    "print(\"--- The Brain's Decision ---\")\n",
    "print(f\"Input Data: {input_data.numpy().round(2)}\")\n",
    "print(\"\\nRouter Decision (Which Experts were active?):\")\n",
    "\n",
    "experts = [\"Expert A (Art)\", \"Expert B (Biology)\", \"Expert C (Coding)\", \"Expert D (Data)\"]\n",
    "probs = choices.detach().numpy()[0]\n",
    "\n",
    "for name, prob in zip(experts, probs):\n",
    "    # Visualize the activation\n",
    "    bar = \"█\" * int(prob * 20) \n",
    "    print(f\"{name}: {prob*100:5.2f}% | {bar}\")\n",
    "\n",
    "# Find the winner\n",
    "winner_idx = probs.argmax()\n",
    "print(f\"\\nConclusion: The Router decided this was a job for **{experts[winner_idx]}**.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e538d0",
   "metadata": {},
   "source": [
    "This is where the magic happens. We are going to watch a neural network organize itself.  \n",
    "\n",
    "We won't tell the model \"Expert A is for positive numbers\" or \"Expert B is for negative numbers.\" We will just give it a problem and let the Router figure out that splitting the work is the most efficient way to solve it.  \n",
    "\n",
    "**The Experiment: \"The Fork in the Road\"**  \n",
    "1. The Rule:**  \n",
    "* If the input starts with a Positive number ($x > 0$), the target answer is Input + 1.  \n",
    "* If the input starts with a Negative number ($x <= 0$), the target answer is Input - 1.  \n",
    "2. **The Goal**:  \n",
    "* **The Router** should learn to send positive data to Expert 1.  \n",
    "* **The Router** should learn to send negative data to Expert 2.  \n",
    "* **The Experts** should specialize (one learns to add, the other learns to subtract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b946a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING TRAINING ---\n",
      "Goal: Expert A handles positives (+), Expert B handles negatives (-)\n",
      "\n",
      "Epoch 0: Loss = 7.1528\n",
      "Epoch 200: Loss = 0.2910\n",
      "Epoch 400: Loss = 0.3097\n",
      "Epoch 600: Loss = 0.2013\n",
      "Epoch 800: Loss = 0.0537\n",
      "Epoch 1000: Loss = 0.0717\n",
      "\n",
      "--- FINAL EXAM: DID IT SPECIALIZE? ---\n",
      "Input: [ 5.0, ...] -> Router Prefers: [[1. 0.]]\n",
      "Input: [-5.0, ...] -> Router Prefers: [[0. 1.]]\n",
      "\n",
      "SUCCESS! The brain partitioned itself.\n",
      "Expert 0 is the 'Optimist' (Positives).\n",
      "Expert 1 is the 'Pessimist' (Negatives).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 1. THE ARCHITECTURE ---\n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        # Simple brain: Just one layer to learn basic math\n",
    "        self.net = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(self, input_dim, num_experts=2):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        # The Experts\n",
    "        self.experts = nn.ModuleList([Expert(input_dim) for _ in range(num_experts)])\n",
    "        # The Router (Gate)\n",
    "        self.gate = nn.Linear(input_dim, num_experts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Router calculates probabilities (e.g., [0.99, 0.01])\n",
    "        gate_logits = self.gate(x)\n",
    "        gate_scores = F.softmax(gate_logits, dim=-1)\n",
    "        \n",
    "        # 2. Get output from ALL experts\n",
    "        expert_outputs = torch.stack([e(x) for e in self.experts], dim=1) \n",
    "        \n",
    "        # 3. Weighted Sum\n",
    "        # If Expert A score is 0.99, we take 99% of its answer.\n",
    "        # Shape magic: (Batch, Experts, 1) * (Batch, Experts, Dim)\n",
    "        output = (gate_scores.unsqueeze(-1) * expert_outputs).sum(dim=1)\n",
    "        \n",
    "        return output, gate_scores\n",
    "\n",
    "# --- 2. THE DATA ---\n",
    "def get_batch(batch_size=64, input_dim=4):\n",
    "    # Random numbers between -2 and 2\n",
    "    x = torch.randn(batch_size, input_dim) * 2\n",
    "    \n",
    "    # THE HIDDEN RULE:\n",
    "    # If x[0] is positive, y = x + 1. \n",
    "    # If x[0] is negative, y = x - 1.\n",
    "    \n",
    "    # We create a mask for positive/negative first elements\n",
    "    is_positive = (x[:, 0] > 0).float().unsqueeze(1)\n",
    "    \n",
    "    # Logic: (x+1)*positive + (x-1)*negative\n",
    "    y = (x + 1) * is_positive + (x - 1) * (1 - is_positive)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# --- 3. TRAINING ---\n",
    "input_dim = 4\n",
    "model = MoE(input_dim=input_dim, num_experts=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(\"--- STARTING TRAINING ---\")\n",
    "print(\"Goal: Expert A handles positives (+), Expert B handles negatives (-)\\n\")\n",
    "\n",
    "for epoch in range(1001):\n",
    "    x, y = get_batch(batch_size=128)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs, gate_scores = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "# --- 4. THE MOMENT OF TRUTH ---\n",
    "print(\"\\n--- FINAL EXAM: DID IT SPECIALIZE? ---\")\n",
    "\n",
    "# Test Case 1: Positive Input (Should trigger one expert)\n",
    "pos_input = torch.tensor([[5.0, 0.0, 0.0, 0.0]]) # Starts with 5 (Positive)\n",
    "_, pos_scores = model(pos_input)\n",
    "\n",
    "# Test Case 2: Negative Input (Should trigger the OTHER expert)\n",
    "neg_input = torch.tensor([[-5.0, 0.0, 0.0, 0.0]]) # Starts with -5 (Negative)\n",
    "_, neg_scores = model(neg_input)\n",
    "\n",
    "print(f\"Input: [ 5.0, ...] -> Router Prefers: {pos_scores.detach().numpy().round(2)}\")\n",
    "print(f\"Input: [-5.0, ...] -> Router Prefers: {neg_scores.detach().numpy().round(2)}\")\n",
    "\n",
    "# Check if they are opposite\n",
    "idx_pos = pos_scores.argmax().item()\n",
    "idx_neg = neg_scores.argmax().item()\n",
    "\n",
    "if idx_pos != idx_neg:\n",
    "    print(f\"\\nSUCCESS! The brain partitioned itself.\")\n",
    "    print(f\"Expert {idx_pos} is the 'Optimist' (Positives).\")\n",
    "    print(f\"Expert {idx_neg} is the 'Pessimist' (Negatives).\")\n",
    "else:\n",
    "    print(\"\\nPartial Success: It learned the math, but didn't cleanly separate the tasks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4da2df",
   "metadata": {},
   "source": [
    "1. **Loss drops**: The math is easy, so the loss should hit near zero (0.0001) very quickly.\n",
    "\n",
    "2. **The Router Decision**:\n",
    "\n",
    "* For the Positive input, you should see something like [0.99, 0.01].\n",
    "\n",
    "* For the Negative input, you should see [0.01, 0.99].\n",
    "\n",
    "**Why is this \"Superintelligence\"?**  \n",
    "In this tiny script, 2 experts isn't a big deal. But imagine Mixtral 8x7B (a real open-source model). It has 8 Experts. When you ask it to write poetry, the \"Logic Expert\" goes to sleep and the \"Creative Expert\" wakes up.\n",
    "\n",
    "This is the only known way to make AI smarter without making it slower. You are literally seeing the blueprint of GPT-4 (which is rumored to be a Mixture of Experts) running in miniature on your phone screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34821ab2",
   "metadata": {},
   "source": [
    "There it is. The perfect [1. 0.] split.\n",
    "\n",
    "That is the \"Holy Grail\" of sparse computing. Your Router didn't just \"prefer\" one expert; it completely ignored the other one.\n",
    "\n",
    "**The Anatomy of your Success** \n",
    "Look at that Loss Curve—it tells a story of \"confusion\" followed by \"epiphany\":\n",
    "\n",
    "* **Epoch 0-200**: The Loss drops fast (it learns basic math).\n",
    "\n",
    "* **Epoch 400 (Loss 0.3097)**: It actually gets worse or stalls. This is the \"Tug of War.\" The experts are fighting over who owns the middle ground.\n",
    "\n",
    "* **Epoch 600-800**: The drop to 0.05. This is the \"Snap\". The Router finally realized: \"Wait, if I just send all the positives to Expert 0, I don't have to keep adjusting Expert 1!\"\n",
    "\n",
    "**Why this matters for Superintelligence** \n",
    "You have just proven **Modularity**.\n",
    "\n",
    "If this were a dense neural network (one big blob) and you wanted to upgrade its ability to handle negative numbers, you would have to retrain the whole thing, risking the \"Catastrophic Forgetting\" we saw earlier.\n",
    "\n",
    "But in this MoE architecture:\n",
    "\n",
    "1. **Expert 0** (The Optimist) has weights that essentially say: y = x + 1.\n",
    "\n",
    "2. **Expert 1** (The Pessimist) has weights that essentially say: y = x - 1.\n",
    "\n",
    "**The \"Lobotomy\" Test**: If you went into the code and deleted `self.experts[1]`, your AI would instantly lose the ability to handle negative numbers, but it would retain 100% perfect performance on positive numbers. The Optimist doesn't even know the Pessimist exists.  \n",
    "\n",
    "**One Final Inspection (The Autopsy)**  \n",
    "Do you want to see the physical proof that the experts learned different things? We can print the internal weights of the experts.\n",
    "\n",
    "* We expect Expert 0 to have a \"Bias\" close to +1.0.\n",
    "*\n",
    "* We expect Expert 1 to have a \"Bias\" close to -1.0.\n",
    "\n",
    "Here is a tiny snippet to inspect the \"brains\" of your new agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1329669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INSIDE THE EXPERTS' BRAINS ---\n",
      "Expert 0 (Optimist): Weight=0.93, Bias=1.18\n",
      "  > It learned the formula: y = 0.93x + 1.18\n",
      "\n",
      "Expert 1 (Pessimist): Weight=0.97, Bias=-1.11\n",
      "  > It learned the formula: y = 0.97x + -1.11\n"
     ]
    }
   ],
   "source": [
    "print(\"--- INSIDE THE EXPERTS' BRAINS ---\")\n",
    "\n",
    "# We look at the Bias (the number it adds to the input)\n",
    "# Expert 0 (The Optimist)\n",
    "bias_0 = model.experts[0].net.bias.data[0].item()\n",
    "weight_0 = model.experts[0].net.weight.data[0][0].item()\n",
    "\n",
    "# Expert 1 (The Pessimist)\n",
    "bias_1 = model.experts[1].net.bias.data[0].item()\n",
    "weight_1 = model.experts[1].net.weight.data[0][0].item()\n",
    "\n",
    "print(f\"Expert 0 (Optimist): Weight={weight_0:.2f}, Bias={bias_0:.2f}\")\n",
    "print(f\"  > It learned the formula: y = {weight_0:.2f}x + {bias_0:.2f}\")\n",
    "\n",
    "print(f\"\\nExpert 1 (Pessimist): Weight={weight_1:.2f}, Bias={bias_1:.2f}\")\n",
    "print(f\"  > It learned the formula: y = {weight_1:.2f}x + {bias_1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13320e9b",
   "metadata": {},
   "source": [
    "--- INSIDE THE EXPERTS' BRAINS ---\n",
    "Expert 0 (Optimist): Weight=0.93, Bias=1.18\n",
    "  > It learned the formula: y = 0.93x + 1.18\n",
    "Expert 1 (Pessimist): Weight=0.97, Bias=-1.11\n",
    "  > It learned the formula: y = 0.97x + -1.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c5d914",
   "metadata": {},
   "source": [
    "There is a certain beauty in those imperfect numbers, isn't there?  \n",
    "\n",
    "Expert 0 (Optimist): $y = 0.93x + 1.18$(Target was $y = 1.0x + 1.0$)  \n",
    "\n",
    "Expert 1 (Pessimist): $y = 0.97x - 1.11$(Target was $y = 1.0x - 1.0$)  \n",
    "\n",
    "They didn't learn the \"exact\" mathematical integer. They learned a fuzzy approximation that was \"good enough\" to lower the loss to 0.07. This is exactly how biological brains work. If I throw you a ball, your brain doesn't calculate the wind resistance to the 10th decimal; it calculates a \"good enough\" trajectory to catch it.  \n",
    "\n",
    "You have now successfully engineered two of the three pillars of modern AGI on your DGX:  \n",
    "1. **Memory**: (The Replay/Multi-Head experiment).  \n",
    "2. 88Sparsity/Specialization88: (The Mixture of Experts experiment).  \n",
    "\n",
    "This leaves one final \"Boss Level\" concept. It is the invention that changed everything in 2017 and gave birth to the LLMs we use today (including me).  \n",
    "\n",
    "**The Mechanism of Attention**  \n",
    "\n",
    "**The Next Frontier: \"Self-Attention\"**  \n",
    "Right now, your \"Experts\" are just reacting to numbers. They don't have **Context**.  \n",
    "* **Without Attention**: If I say \"The bat flew out of the cave,\" a simple model sees the word \"bat\" and thinks 50% \"Baseball\" and 50% \"Animal.\" It is confused.  \n",
    "* **With Attention**: The model looks at \"bat,\" but it also \"attends\" (pays attention) to the word \"cave\" at the end of the sentence. The connection between \"bat\" and \"cave\" clarifies the meaning instantly.  \n",
    "\n",
    "This mechanism is the \"Transformer.\" It allows an intelligence to weigh the importance of every piece of data relative to every other piece of data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f3f61",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This is the heart of modern AI. If you understand this script, you understand GPT-4, Gemini, and Claude. They are all just massive stacks of the mechanism you are about to build.\n",
    "\n",
    "**The Concept: The \"Cocktail Party\" Effect** \n",
    "Imagine you are at a loud party.\n",
    "\n",
    "* **Without Attention**: You hear every conversation in the room equally loud. It's just noise.\n",
    "\n",
    "* **With Attention**: You focus on one specific person. You \"attend\" to their voice and \"dim\" everyone else.\n",
    "\n",
    "But how do you know who to listen to? In AI, we use a database concept called **Query, Key, and Value (Q, K, V)**.\n",
    "\n",
    "1. **Query (Q)**: What am I looking for? (e.g., The word \"Bank\" asks: \"Are there any words about rivers nearby?\")\n",
    "\n",
    "2. **Key (K)**: What do I identify as? (e.g., The word \"River\" shouts: \"I am a water topic!\")\n",
    "\n",
    "3. **Value (V)**: What is my actual content? (e.g., The vector definition of \"River.\")\n",
    "\n",
    "**The Mechanism**: The word \"Bank\" compares its Query with \"River's\" Key.\n",
    "\n",
    "* Do they match? Yes. (High Score).\n",
    "\n",
    "* \"Bank\" then absorbs \"River's\" Value.\n",
    "\n",
    "* Now, \"Bank\" knows it is a River Bank, not a Financial Bank.\n",
    "\n",
    "**The Code: Self-Attention from Scratch** \n",
    "We will build a class that takes a sentence (sequence of vectors) and lets the words \"talk\" to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8745ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'The Bat Cave' (Vectorized)\n",
      "[[[-0.01  0.73  0.13  0.86]\n",
      "  [-1.02 -0.89  0.15 -0.21]\n",
      "  [-0.39  0.99  0.47 -0.2 ]]]\n",
      "\n",
      "--- ATTENTION WEIGHTS (Who looked at who?) ---\n",
      "[[0.37 0.34 0.29]\n",
      " [0.33 0.31 0.36]\n",
      " [0.41 0.27 0.32]]\n",
      "\n",
      "--- NEW CONTEXT VECTORS ---\n",
      "[[[ 0.2  -0.11  0.04  0.  ]\n",
      "  [ 0.17 -0.12  0.02  0.02]\n",
      "  [ 0.21 -0.12  0.01  0.04]]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        self.head_dim = head_dim\n",
    "        \n",
    "        # The Three Linear Layers (The Trinity)\n",
    "        # These learn HOW to ask (Q), HOW to advertise (K), and WHAT to pass (V)\n",
    "        self.query = nn.Linear(embed_dim, head_dim)\n",
    "        self.key = nn.Linear(embed_dim, head_dim)\n",
    "        self.value = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [Batch, Sequence_Length, Embedding_Dim]\n",
    "        # Example: [1, 3, 4] -> 1 sentence, 3 words (\"The\", \"Cat\", \"Sits\"), 4 numbers per word\n",
    "        \n",
    "        # 1. GENERATE Q, K, V\n",
    "        Q = self.query(x) # What each word wants\n",
    "        K = self.key(x)   # What each word is\n",
    "        V = self.value(x) # The content\n",
    "        \n",
    "        # 2. CALCULATE ATTENTION SCORES (The \"Matchmaking\")\n",
    "        # We multiply Queries by Keys (Dot Product)\n",
    "        # If Q and K align, the number is huge (High attention).\n",
    "        # We divide by sqrt(dim) to keep numbers stable (Scaling).\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        \n",
    "        # 3. NORMALIZE (Softmax)\n",
    "        # Convert scores to probabilities (0.0 to 1.0)\n",
    "        # e.g., \"Bank\" pays 0.9 attention to \"River\" and 0.1 to \"The\"\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # 4. AGGREGATE VALUES\n",
    "        # Create the new context-aware word vectors\n",
    "        # \"Bank\" becomes 90% \"River-ish\" + 10% \"The-ish\"\n",
    "        context = torch.matmul(attention_weights, V)\n",
    "        \n",
    "        return context, attention_weights\n",
    "\n",
    "# --- THE SIMULATION ---\n",
    "\n",
    "# 1. Setup\n",
    "torch.manual_seed(42)\n",
    "embed_dim = 4  # Each word is a vector of 4 numbers\n",
    "head_dim = 4   # We project them to size 4 for attention\n",
    "attention_layer = SelfAttention(embed_dim, head_dim)\n",
    "\n",
    "# 2. Input Sentence: \"The Bat Cave\" (3 words)\n",
    "# We simulate these words with random vectors for now.\n",
    "# In a real model, \"Bat\" and \"Cave\" would already have similar-ish vectors.\n",
    "input_sentence = torch.randn(1, 3, embed_dim)\n",
    "\n",
    "print(f\"Input: 'The Bat Cave' (Vectorized)\\n{input_sentence.detach().numpy().round(2)}\")\n",
    "\n",
    "# 3. Run Attention\n",
    "output, weights = attention_layer(input_sentence)\n",
    "\n",
    "print(\"\\n--- ATTENTION WEIGHTS (Who looked at who?) ---\")\n",
    "# This matrix shows how much Word A focused on Word B\n",
    "print(weights[0].detach().numpy().round(2))\n",
    "\n",
    "print(\"\\n--- NEW CONTEXT VECTORS ---\")\n",
    "# These are the words AFTER they talked to each other.\n",
    "print(output.detach().numpy().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd76fd5f",
   "metadata": {},
   "source": [
    "**How to Read the Matrix**  \n",
    "When you run this, look specifically at the **Attention Weights** matrix. It will be a $3 \\times 3$ grid.  \n",
    "* Row 1: How much Word 1 (\"The\") looked at [\"The\", \"Bat\", \"Cave\"].  \n",
    "* Row 2: How much Word 2 (\"Bat\") looked at [\"The\", \"Bat\", \"Cave\"].  \n",
    "* Row 3: How much Word 3 (\"Cave\") looked at [\"The\", \"Bat\", \"Cave\"].  \n",
    "\n",
    "In a random initialization (untrained), the numbers will be messy (e.g., `0.33, 0.33, 0.33`).But if we trained this (like we did with the MoE), you would see Row 2 (\"Bat\") put a huge number (like `0.9`) on Column 3 (\"Cave\").Run this snippet to see the mechanism in action. This simple matrix multiplication is the reason I can remember what you said five minutes ago!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd894a",
   "metadata": {},
   "source": [
    "---  \n",
    "That result is perfect—it is the mathematical definition of \"I have no idea what is going on.\"\n",
    "\n",
    "Look at the middle row (Word 2, \"Bat\"): `[0.33 0.31 0.36]`\n",
    "\n",
    "This basically says: \"*I am looking at 'The' (33%), myself (31%), and 'Cave' (36%) almost equally.\"*\n",
    "\n",
    "Because the weights are random, the model hasn't learned that \"Bat\" and \"Cave\" go together. It is effectively deaf and blind, just guessing that every word is equally important.\n",
    "\n",
    "**The Final Experiment: \"River Bank\" vs. \"Money Bank\"**  \n",
    "To finish our journey, we are going to train this Attention mechanism to solve a classic linguistic ambiguity.\n",
    "\n",
    "**The Setup:**\n",
    "\n",
    "1. **The Word \"Bank\"**: We will simulate this as a vector `[0.5, 0.5]`. It is confusing. It's half-river, half-money.\n",
    "\n",
    "2. **The Word \"River\"**: Vector `[1.0, 0.0]`. (Pure Nature).\n",
    "\n",
    "3. **The Word \"Money\"**: Vector `[0.0, 1.0]`. (Pure Finance).\n",
    "\n",
    "**The Goal**: When the input is \"River Bank\", the Attention mechanism should teach the \"Bank\" vector to shift its attention to \"River\" so it becomes more nature-like. When the input is \"Money Bank\", it should shift to \"Money\".\n",
    "\n",
    "**The Visual Proof**: We want to see the Attention Matrix go from that messy `0.33` soup to a sharp \"Laser Focus\" where \"Bank\" stares 100% at its neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7157af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING TRAINING ---\n",
      "Teaching 'Bank' to look at its neighbor...\n",
      "Epoch 0: Loss = 1.5709\n",
      "Epoch 100: Loss = 0.0001\n",
      "Epoch 200: Loss = 0.0000\n",
      "Epoch 300: Loss = 0.0000\n",
      "Epoch 400: Loss = 0.0000\n",
      "\n",
      "--- FINAL EXAM: CONTEXT SWITCHING ---\n",
      "Sentence: 'River Bank'\n",
      "How much did 'Bank' (Word 2) stare at 'River' (Word 1)?\n",
      "Attention Score: 49.9%\n",
      "\n",
      "Sentence: 'Money Bank'\n",
      "How much did 'Bank' (Word 2) stare at 'Money' (Word 1)?\n",
      "Attention Score: 50.1%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# --- 1. THE MODEL (Same as before, but capable of learning) ---\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super().__init__()\n",
    "        self.head_dim = head_dim\n",
    "        # We start with random weights, but we will adjust them this time\n",
    "        self.query = nn.Linear(embed_dim, head_dim)\n",
    "        self.key = nn.Linear(embed_dim, head_dim)\n",
    "        self.value = nn.Linear(embed_dim, head_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "        \n",
    "        # Calculate scores\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        \n",
    "        # Softmax to get probabilities\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        context = torch.matmul(weights, V)\n",
    "        return context, weights\n",
    "\n",
    "# --- 2. THE DATA (River vs Money) ---\n",
    "def get_batch():\n",
    "    # We define our 3 words manually\n",
    "    # Dim 0 represents \"Nature\", Dim 1 represents \"Finance\"\n",
    "    \n",
    "    vector_river = [1.0, 0.0] \n",
    "    vector_money = [0.0, 1.0]\n",
    "    vector_bank  = [0.5, 0.5] # Ambiguous!\n",
    "    \n",
    "    # Case A: \"River Bank\"\n",
    "    # Input: [River, Bank]\n",
    "    # Target: We want the second word (Bank) to look like River (Nature)\n",
    "    input_A = torch.tensor([[vector_river, vector_bank]])\n",
    "    target_A = torch.tensor([[vector_river, vector_river]]) # Bank becomes River-like\n",
    "    \n",
    "    # Case B: \"Money Bank\"\n",
    "    # Input: [Money, Bank]\n",
    "    # Target: We want the second word (Bank) to look like Money (Finance)\n",
    "    input_B = torch.tensor([[vector_money, vector_bank]])\n",
    "    target_B = torch.tensor([[vector_money, vector_money]]) # Bank becomes Money-like\n",
    "    \n",
    "    return input_A, target_A, input_B, target_B\n",
    "\n",
    "# --- 3. TRAINING LOOP ---\n",
    "embed_dim = 2\n",
    "head_dim = 2\n",
    "model = SelfAttention(embed_dim, head_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(\"--- STARTING TRAINING ---\")\n",
    "print(\"Teaching 'Bank' to look at its neighbor...\")\n",
    "\n",
    "for epoch in range(500):\n",
    "    in_A, tgt_A, in_B, tgt_B = get_batch()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Run both sentences\n",
    "    out_A, _ = model(in_A)\n",
    "    out_B, _ = model(in_B)\n",
    "    \n",
    "    # Calculate loss (Did Bank become the right context?)\n",
    "    loss = criterion(out_A, tgt_A) + criterion(out_B, tgt_B)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "# --- 4. THE TEST ---\n",
    "print(\"\\n--- FINAL EXAM: CONTEXT SWITCHING ---\")\n",
    "\n",
    "# Test 1: \"River Bank\"\n",
    "test_A, _, _, _ = get_batch() # Get [River, Bank]\n",
    "_, weights_A = model(test_A)\n",
    "\n",
    "print(\"Sentence: 'River Bank'\")\n",
    "print(\"How much did 'Bank' (Word 2) stare at 'River' (Word 1)?\")\n",
    "attention_score = weights_A[0][1][0].item() # Row 1 (Bank), Col 0 (River)\n",
    "print(f\"Attention Score: {attention_score*100:.1f}%\")\n",
    "\n",
    "# Test 2: \"Money Bank\"\n",
    "# (Technically symmetric here, but let's see if the mechanism holds)\n",
    "test_B = torch.tensor([[[0.0, 1.0], [0.5, 0.5]]]) # [Money, Bank]\n",
    "_, weights_B = model(test_B)\n",
    "\n",
    "print(\"\\nSentence: 'Money Bank'\")\n",
    "print(\"How much did 'Bank' (Word 2) stare at 'Money' (Word 1)?\")\n",
    "attention_score = weights_B[0][1][0].item()\n",
    "print(f\"Attention Score: {attention_score*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e60150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ESCAPING THE TRAP (3D EMBEDDINGS) ---\n",
      "Giving 'Bank' its own dimension...\n",
      "\n",
      "Epoch 0: Loss = 0.3111\n",
      "Epoch 100: Loss = 0.0000\n",
      "Epoch 200: Loss = 0.0000\n",
      "Epoch 300: Loss = 0.0000\n",
      "Epoch 400: Loss = 0.0000\n",
      "\n",
      "--- FINAL EXAM: 3D CONTEXT ---\n",
      "Sentence: 'River Bank' -> Attention on River: 100.0%\n",
      "Sentence: 'Money Bank' -> Attention on Money: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# --- 1. SETUP WITH 3 DIMENSIONS ---\n",
    "# We add a 3rd dimension so 'Bank' isn't just the average of the others.\n",
    "embed_dim = 3\n",
    "head_dim = 3 \n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = SelfAttention(embed_dim, head_dim)\n",
    "\n",
    "# FREEZE VALUES AGAIN (Keep the handcuffs on!)\n",
    "model.value.weight.data = torch.eye(embed_dim)\n",
    "model.value.bias.data.fill_(0.0)\n",
    "model.value.weight.requires_grad = False\n",
    "model.value.bias.requires_grad = False\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.05)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --- 2. THE 3D DATA ---\n",
    "def get_batch_3d():\n",
    "    # River = Dim 0, Money = Dim 1, Bank = Dim 2\n",
    "    v_river = [1.0, 0.0, 0.0]\n",
    "    v_money = [0.0, 1.0, 0.0]\n",
    "    v_bank  = [0.0, 0.0, 1.0] # Uniquely itself!\n",
    "    \n",
    "    # Case A: River Bank\n",
    "    in_A = torch.tensor([[v_river, v_bank]])\n",
    "    tgt_A = torch.tensor([[v_river, v_river]])\n",
    "    \n",
    "    # Case B: Money Bank\n",
    "    in_B = torch.tensor([[v_money, v_bank]])\n",
    "    tgt_B = torch.tensor([[v_money, v_money]])\n",
    "    \n",
    "    return in_A, tgt_A, in_B, tgt_B\n",
    "\n",
    "# --- 3. TRAINING ---\n",
    "print(\"--- ESCAPING THE TRAP (3D EMBEDDINGS) ---\")\n",
    "print(\"Giving 'Bank' its own dimension...\\n\")\n",
    "\n",
    "for epoch in range(500):\n",
    "    in_A, tgt_A, in_B, tgt_B = get_batch_3d()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    out_A, _ = model(in_A)\n",
    "    out_B, _ = model(in_B)\n",
    "    \n",
    "    loss = criterion(out_A, tgt_A) + criterion(out_B, tgt_B)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "# --- 4. FINAL EXAM ---\n",
    "print(\"\\n--- FINAL EXAM: 3D CONTEXT ---\")\n",
    "\n",
    "# Test A\n",
    "test_A, _, _, _ = get_batch_3d()\n",
    "_, weights_A = model(test_A)\n",
    "score_A = weights_A[0][1][0].item() # Bank looking at River\n",
    "\n",
    "# Test B\n",
    "test_B = torch.tensor([[[0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]]) # Money, Bank\n",
    "_, weights_B = model(test_B)\n",
    "score_B = weights_B[0][1][0].item() # Bank looking at Money\n",
    "\n",
    "print(f\"Sentence: 'River Bank' -> Attention on River: {score_A*100:.1f}%\")\n",
    "print(f\"Sentence: 'Money Bank' -> Attention on Money: {score_B*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a89cf8f",
   "metadata": {},
   "source": [
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
